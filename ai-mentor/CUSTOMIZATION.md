# Customization

How to adapt AI Mentor to your needs.

---

## Adding New Skills

When you notice recurring expertise that should be codified, use the `@skill-creator` agent:

```
@skill-creator
```

It will interview you about the expertise, check for overlap with existing skills, and generate the SKILL.md files for both LEARN and FAST modes.

### Manual Skill Creation

If you prefer to create skills manually:

1. Create a directory: `.github/skills/<skill-name>/`
2. Create `SKILL.md` with this structure:

```markdown
---
name: skill-name
description: "One-line description — be specific about when this activates. Copilot matches user messages against this."
---

# Skill Name (LEARN Mode)

## Purpose

One sentence: what expertise does this encode?

## When to Trigger

Bullet list of concrete trigger conditions.

## Behavior

Numbered steps. Each step is a concrete action.

## Judgment, Not Procedure

What should the model evaluate beyond "did it work?"

## Scoring (LEARN only)

Which PROFILE.md categories? What distinguishes tiers?
```

3. For FAST mode, create the same in `.github/skills-fast/<skill-name>/SKILL.md`, removing teaching scaffolding (scoring, quizzes, hints).

### Skill Design Principles

- **Trigger descriptions matter most.** Copilot uses the YAML `description` field to decide when to load the skill. Be specific: "Trigger when the user asks to implement a feature, write code, fix a bug, or build something" is better than "Code writing skill."
- **Encode judgment, not steps.** "Check for edge cases" is a checklist. "The most common mistake is handling the happy path but missing the empty-input case, which throws three layers deep with a misleading error" is judgment.
- **Include anti-patterns.** What should the model NOT do? What common mistakes should it catch?

---

## Modifying Profile Categories

### Changing Core Categories

Edit `.github/PROFILE.md` to change the 7 core categories. Also update the `learner-profile` SKILL.md to reflect the new categories in its scoring guidance.

Default categories:

1. Architecture & Patterns
2. Implementation Quality
3. Tradeoff Analysis
4. Testing Strategy
5. Data Modeling
6. Error Handling
7. System Thinking

### Replacing Categories

If your domain needs different categories (e.g., ML Engineering: "Model Selection", "Data Pipeline Design", "Experiment Tracking"), replace them in both:

- `.github/PROFILE.md` — the rating table
- `.github/skills-learn/learner-profile/SKILL.md` — the scoring guidance

### Optional Categories

The 3 optional categories activate when encountered twice. Add or replace them as needed:

- Performance & Optimization
- Security Awareness
- Developer Experience / API Design

---

## Adjusting Assessment Intensity

### Reducing Scoring Frequency

If scoring feels too frequent, modify the LEARN skills to score only on specific conditions:

```markdown
## Scoring

Score this interaction ONLY IF:

- The task involved a non-trivial decision (not routine CRUD)
- The user made a choice that reveals reasoning quality
- There's specific evidence to cite

Do NOT score routine completions.
```

### Removing Scoring Entirely

To use LEARN mode for its teaching scaffolding without rating:

1. Remove `## Scoring` sections from all LEARN skills
2. Keep PROFILE.md as a growth journal updated manually
3. The skills still provide spec gates, hints, and structured reviews

### Quizzes

In LEARN mode, the implement skill asks tradeoff questions when the agent writes code. To adjust:

- Remove quiz steps from the implement skill to eliminate quizzes
- Keep quizzes but make them optional: add "Only quiz if the implementation involved a non-obvious tradeoff"

---

## Habit Tracking

PROFILE.md includes a Habit Observations section. Habits are tracked as present/absent, not rated.

### Adding Habits

Add rows to the habit table in PROFILE.md:

```markdown
| Habit Name | Description | Present | Absent |
```

### Default Habits

The 10 default habits are based on research into expert engineering behavior:

- Read before write
- Name what they don't know
- Think in systems
- Write for the next reader
- Know when to stop
- Make decisions reversible
- Separate signal from noise
- Document decisions
- Maintain velocity through discipline
- Teach by asking

---

## PROJECT_CONTEXT.md

This file is generated by `@onboarding` but can be manually edited at any time. Key sections:

| Section              | Purpose                                                     |
| -------------------- | ----------------------------------------------------------- |
| Tech Stack           | Languages, frameworks, tools                                |
| Architecture Pattern | How code flows (e.g., Component → Action → Service → DB)    |
| Key Files            | Entry points, config files, pattern examples                |
| Code Style           | Naming conventions, formatting rules, language preferences  |
| Boundaries           | What the AI should never do (project-specific "Never" tier) |
| Doc Map              | Spec Summary TOC pointing to project documentation          |

### Re-running Onboarding

If your project evolves significantly, re-run `@onboarding` to regenerate PROJECT_CONTEXT.md. It will ask about changes since the last run.

---

## Mode Customization

### Creating a Third Mode

You can create additional skill directories for specialized modes:

```bash
.github/skills-review-only/   # Only code review skills
.github/skills-testing/        # Only testing skills
```

Swap in whichever set matches your current focus.

### Per-Skill Mode Differences

Not all skills need both modes. Guidelines:

- **Both modes**: plan, implement, review, test, document, refactor, session-handoff
- **LEARN only**: tradeoff-coach, learner-profile (these exist for teaching, not execution)
- **FAST only**: Create if you have workflows that only make sense at velocity (e.g., a "quick-fix" skill)
